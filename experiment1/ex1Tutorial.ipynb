{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Remove dodgy images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imghdr#拡張子をファイルの文字を参照するのではなく、構造を参照するファイル判定モジュール。\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ディレクトリ名を指定\n",
    "data_dir = 'snake_images' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#受けつける拡張子の指定\n",
    "image_exts = ['jpeg','jpg', 'bmp', 'png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#.DS_Storeがあるか確認。\n",
    "for image_class in os.listdir(data_dir): \n",
    "    print(image_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のコードで.DS_Storeディレクトリを消去する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for image_class in os.listdir(data_dir):\n",
    "    if image_class == '.DS_Store':\n",
    "        file_path = os.path.join(data_dir, image_class)\n",
    "        os.remove(file_path)\n",
    "    else:\n",
    "        print(image_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.DS_Storeが消えているのを確認\n",
    "for image_class in os.listdir(data_dir): \n",
    "    print(image_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#対象としていない拡張子と壊れている画像ファイルをremoveする。\n",
    "for image_class in os.listdir(data_dir): \n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try: \n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in image_exts: \n",
    "                print('Image not in ext list {}'.format(image_path))\n",
    "                os.remove(image_path)\n",
    "        except Exception as e: \n",
    "            print('Issue with image {}'.format(image_path))\n",
    "            os.remove(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0と1がどのクラスに対応しているのかを出力する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {}  # クラス名とラベルの対応付けを格納する辞書\n",
    "\n",
    "for label, image_class in enumerate(os.listdir(data_dir)):\n",
    "    if image_class == '.DS_Store':\n",
    "        file_path = os.path.join(data_dir, image_class)\n",
    "        os.remove(file_path)\n",
    "    else:\n",
    "        class_name = image_class.split('_')[0]\n",
    "        print(f\"{class_name}: {label}\")\n",
    "        class_mapping[label] = class_name\n",
    "\n",
    "# class_mapping辞書を修正して、ラベルを0と1に変更する。\n",
    "class_mapping = {label: label - 1 for label in class_mapping}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#指定されたディレクトリから画像データセットを作成\n",
    "data = tf.keras.utils.image_dataset_from_directory('snake_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データセットの要素をnumpy配列として返すiteratorを作成。\n",
    "data_iterator = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#イテレータから次のバッチを取得する\n",
    "batch = data_iterator.next()\n",
    "\n",
    "#batch0:画像データ\n",
    "#batch1: 0 or1（毒あり or 毒なしラベル）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#バッチの上から４つ選び、プロットする。\n",
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img.astype(int))\n",
    "    ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Scale Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x:image\n",
    "#y:target\n",
    "#scale data to 0 through 1\n",
    "data = data.map(lambda x,y: (x/255, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#データセットの要素をnumpy配列として返すiteratorを作成。\n",
    "#イテレータから次のバッチを取得する\n",
    "batch = data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#スケーリングしたデータセットのバッチの上から４つ選び、プロットする。\n",
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img)\n",
    "    ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Split Data to train,test,vallidating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#バッチ数をプリント\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_size = int(len(data)*.7)\n",
    "val_size = int(len(data)*.2)\n",
    "test_size = int(len(data)*.1)+1 #hold until the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下の3変数の合計がlen(data)分になるようにする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take():how much we take from dataset\n",
    "#skip():usually,skip take() area \n",
    "\n",
    "train = data.take(train_size)#train model\n",
    "val = data.skip(train_size).take(val_size)#evaluate model\n",
    "test = data.skip(train_size+val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Build Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlowで新しいシーケンシャルモデルを作成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#空のシーケンシャルモデルを作成\n",
    "#シーケンシャルモデル:ニューラルネットワークモデルを構築するための層の線形スタック\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add()メソッドを使用してモデルにレイヤーを追加します。\n",
    "#各レイヤーは、フォワードパス中にデータが通過する特定の操作や変換を表す。\n",
    "\n",
    "#これらをシーケンシャルクラスにスタックする。\n",
    "\n",
    "\n",
    " #Conv2D's args:(number of filters,(size of the filter),stride,activation func-name,input shape)\n",
    "# 最初の層にはinput_shapeの入力が必要\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3))) \n",
    "#2x2フィルタから最大値を取る。\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "#1次元にする\n",
    "model.add(Flatten())\n",
    "\n",
    "#全結合層\n",
    "#256個の値が出力されるようにする\n",
    "model.add(Dense(256, activation='relu'))\n",
    "#単一の出をと0か1にマップする。\n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデルのコンパイルを行う。\n",
    "\n",
    "#Adamオプティマイザーを使用\n",
    "#tf.losses.BinaryCrossentropy()を指定して損失関数として二値交差エントロピーを使用する。\n",
    "#評価関数としてaccuracyを使用する.\n",
    "\n",
    "model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#モデルの構造を表示。\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ログファイルを保存するディレクトリを指定\n",
    "logdir='logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit間数にわたすため、コールバックを作成\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fit:training\n",
    "#epocs:how long we 're actually going to go ahead and train for\n",
    "\n",
    "hist = model.fit(train, epochs=5, validation_data=val, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#返されたオブジェクトのhistory属性を使ってアクセス。\n",
    "hist.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Plot Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lossとval_lossをプロット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracyとval_accuracyをプロット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習済みモデルの評価を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#精度、再現率、および二値分類精度を計算し、\n",
    "#真のラベルyと予測されたラベルyhatを比べる\n",
    "for batch in test.as_numpy_iterator(): \n",
    "    X, y = batch\n",
    "    yhat = model.predict(X)\n",
    "    pre.update_state(y, yhat)\n",
    "    re.update_state(y, yhat)\n",
    "    acc.update_state(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#それぞれの出力値は1に近いほどよい\n",
    "print(pre.result(), re.result(), acc.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデルが一度も見たことがない画像1枚を渡す\n",
    "img = cv2.imread('p.png')\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#画像の前処理を行う\n",
    "resize = tf.image.resize(img, (256,256))\n",
    "plt.imshow(resize.numpy().astype(int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#前処理をした画像をモデルに入力し、予測を行う。\n",
    "yhat = model.predict(np.expand_dims(resize/255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#予測値が 0.5 より大きい場合は、「予測されたクラスは非毒性」と表示される。\n",
    "#それ以外の場合は、「予測されたクラスは有毒」と表示。\n",
    "if yhat > 0.5: \n",
    "    print(f'Predicted class is non-poisonous')\n",
    "else:\n",
    "    print(f'Predicted class is poisonous')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Save the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習モデルの保存を行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelsフォルダに学習済みモデルを保存\n",
    "model.save(os.path.join('models','snake_poisonClassifier1.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存したモデルをloadする\n",
    "new_model = load_model(os.path.join('models','snake_poisonClassifier1.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデルが一度も見たことがない画像1枚を渡し、予測を行う。\n",
    "yhatnew = new_model.predict(np.expand_dims(resize/255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#予測値が 0.5 より大きい場合は、「予測されたクラスは非毒性」と表示される。\n",
    "#それ以外の場合は、「予測されたクラスは有毒」と表示。\n",
    "if yhat > 0.5: \n",
    "    print(f'Predicted class is non-poisonous')\n",
    "else:\n",
    "    print(f'Predicted class is poisonous')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
